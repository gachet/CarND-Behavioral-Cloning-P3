{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything at the begining (My past as a C/C++ programmer betrays me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from random import shuffle\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an initial model. I don't agree to much with the idea of doing subsampling (stride>1) in the convolutional layers, as I read in multiple places that is more destructive than using a pooling layer after the convolutional one without subsampling, but let's give it an oportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_nvidia(image_shape):\n",
    "    \"\"\"\n",
    "    End to End Learning for Self-Driving Cars\n",
    "    http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "    \n",
    "    No info is provided for activations, hence I choose RELU\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    '''\n",
    "    def normalize(x, a, b):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Use a lambda layer to normalize the input data\n",
    "    #model.add(Lambda(lambda x: normalize(x, 0, 1), input_shape=image_shape, output_shape=image_shape))\n",
    "    # Removed Lambda layer. Seems to add more troubles than it helps.\n",
    "    model.add(Convolution2D(nb_filter=24, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2), input_shape=image_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=36, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=48, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Activation('relu'))     \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I want to play with optimizers later, but for the moment, a standard adam should be more than fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    return Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'s define some hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2models = \"./models/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "\n",
    "def train_model(train_gen, val_gen, batch_size, epochs, model, optimizer=None):\n",
    "    \n",
    "    if optimizer:\n",
    "        model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\") # This is a nice optimizer to be left as default\n",
    "        \n",
    "    # Callbacks\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(factor=0.5, patience=3, cooldown=3, min_lr=1e-5)\n",
    "    checkpoint = ModelCheckpoint(filepath=path2models)\n",
    "    early_stopping = EarlyStopping(min_delta=2*1e-3, patience=7)\n",
    "    \n",
    "    ls_callbacks = [checkpoint, reduce_lr_on_plateau, early_stopping]\n",
    "    \n",
    "    \n",
    "    #history = model.fit(X_train, Y_train, batch_size=Batch_size, nb_epoch=Epoch, callbacks=ls_callbacks)\n",
    "    \n",
    "    samples_per_epoch = train_gen.get_epoch_size()\n",
    "    nb_epoch = epochs\n",
    "    nb_val_samples = 1 # TODO\n",
    "    nb_worker = 1 # p2.xlarge instance has 4 CPU threads\n",
    "    history = model.fit_generator(train_gen, samples_per_epoch, nb_epoch, \\\n",
    "                                  nb_val_samples=nb_val_samples, validation_data=val_gen, nb_worker=nb_worker, \\\n",
    "                                  callbacks=ls_callbacks)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data with a python generator so we can do data augmentation on the fly\n",
    "\n",
    "class My_dataset_gen():\n",
    "    \"\"\"\n",
    "    To be strict, My_dataset_gen is not a real generator (does not call yield) but an iterator\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 path2csv,\n",
    "                 batch_size,\n",
    "                 crop_input,\n",
    "                 training=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.crop_input = crop_input\n",
    "        \n",
    "        # Load the CSV\n",
    "        self.path2csv = path2csv\n",
    "        df = pd.read_csv(self.path2csv)\n",
    "        self.dataset = df.to_dict(orient='records') # This is a list of dict\n",
    "        \n",
    "        self.position = 0\n",
    "        self.size_epoch = len(self.dataset)\n",
    "        self.training = training\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        number_of_samples = 0\n",
    "        X_l = list()\n",
    "        Y_l = list()\n",
    "        \n",
    "        while number_of_samples < self.batch_size:\n",
    "            if self.position == self.size_epoch:\n",
    "                shuffle(self.dataset)\n",
    "                self.position = 0\n",
    "                \n",
    "            sample = self.dataset[self.position]\n",
    "            \n",
    "            if self.training:\n",
    "                rand_val = random.random()\n",
    "            else:\n",
    "                rand_val = -1\n",
    "                \n",
    "            if rand_val <= 1-sample['Probability appearance']: # This way we eliminate biases toward more frequent values\n",
    "                # E.g. sample['Probability appearance'] = 0.25. This means it appears  only 25% of the times in the dataset\n",
    "                # but I want to balance it, so I do 1-0.25= 0.75. Comparing with a random value between 0 and 1, this sample \n",
    "                # will be used (with data augmentation techniques) the 75% of the times. Category samples with a high \n",
    "                # 'Probability appearance' will be more likely rejected, but because of there are more samples of that \n",
    "                # category doesn't matter. On average all categories should be balanced.\n",
    "                image = imread(sample['Updated image path'])\n",
    "                image = self._crop(image)\n",
    "                angle = sample['Steering angle']\n",
    "                \n",
    "                if self.training:\n",
    "                    image, angle = self._random_transform(image, angle)\n",
    "                    \n",
    "                image = self._normalize(image)\n",
    "                \n",
    "                X_l.append(image)\n",
    "                Y_l.append(angle)\n",
    "                \n",
    "                number_of_samples += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "            self.position += 1\n",
    "            \n",
    "            \n",
    "        X = np.array(X_l) # Current shape follows tf dim_ordering: (samples, height, width, channels)\n",
    "        Y = np.array(Y_l)\n",
    "        \n",
    "        return (X,Y)\n",
    "            \n",
    "    \n",
    "    def _normalize(self, x, a=0, b=1):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    \n",
    "    def _crop(self, x):\n",
    "            return x[50:150, :] # See Explore dataset + Experimental setup.ipynb\n",
    "\n",
    "    def _random_transform(self, image, angle):\n",
    "        return image, angle # TODO to be completed\n",
    "    \n",
    "    def get_image_shape(self):\n",
    "        \n",
    "        temp = imread(self.dataset[0]['Updated image path'])\n",
    "        \n",
    "        if self.crop_input:\n",
    "            return self._crop(temp).shape\n",
    "        else:\n",
    "            return temp.shape\n",
    "        \n",
    "    def get_epoch_size(self):\n",
    "        return self.size_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path2csv_training = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_training.csv\"\n",
    "path2csv_validation = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_validation.csv\"\n",
    "\n",
    "# TODO delete the next 2 lines\n",
    "batch_size = 4\n",
    "epochs = 2\n",
    "crop_input = True\n",
    "\n",
    "train_gen = My_dataset_gen(path2csv_training, batch_size, crop_input)\n",
    "val_gen = My_dataset_gen(path2csv_validation, batch_size, crop_input, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO resampling (10 Hz sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_11 (Convolution2D) (None, 48, 158, 24)   1824        convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 48, 158, 24)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 22, 77, 36)    21636       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 22, 77, 36)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 9, 37, 48)     43248       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 9, 37, 48)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 7, 35, 64)     27712       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 7, 35, 64)     0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 5, 33, 64)     36928       activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 5, 33, 64)     0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 10560)         0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 1164)          12293004    flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 1164)          0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 100)           116500      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 100)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 50)            5050        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 50)            0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 10)            510         activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 10)            0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1)             11          activation_27[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 12,546,423\n",
      "Trainable params: 12,546,423\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_nvidia(train_gen.get_image_shape())\n",
    "optimizer = get_optimizer()\n",
    "\n",
    "# Just have a look at our model before training:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   68/26050 [..............................] - ETA: 2260s - loss: 0.0192"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d478bd753aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# There is no need to save the model. It's already saved by the callbacks provided in fit_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d72b6f2c2de4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_gen, val_gen, batch_size, epochs, model, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mnb_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# p2.xlarge instance has 4 CPU threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mls_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1900\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/programs/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history, model = train_model(train_gen, val_gen, batch_size, epochs, model, optimizer)\n",
    "# There is no need to save the model. It's already saved by the callbacks provided in fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_vs_epochs(training_loss, validation_loss)\n",
    "    plt.plot(range(1,len(training_loss)+1), training_loss, 'b')\n",
    "    plt.xticks(range(1,len(training_loss)+1))\n",
    "    plt.hold(True)\n",
    "    plt.plot(range(1,len(training_loss)+1), validation_loss, 'g')\n",
    "    plt.hold(False)\n",
    "    _ = plt.legend((\"Training\", \"Validation\"), loc='lower right')\n",
    "    _ = plt.ylabel(\"Loss\")\n",
    "    _ = plt.xlabel(\"Epochs\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-TensorFlow-Lab]",
   "language": "python",
   "name": "conda-env-CarND-TensorFlow-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
