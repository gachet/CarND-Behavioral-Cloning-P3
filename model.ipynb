{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything at the begining (My past as a C/C++ programmer betrays me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy.misc import imread\n",
    "from random import shuffle\n",
    "import data_augmentation_toolkit as data_aug\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an initial model. I don't agree to much with the idea of doing subsampling (stride>1) in the convolutional layers, as I read in multiple places that is more destructive than using a pooling layer after the convolutional one without subsampling, but let's give it an oportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_nvidia(image_shape):\n",
    "    \"\"\"\n",
    "    End to End Learning for Self-Driving Cars\n",
    "    http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "    \n",
    "    No info is provided for activations, hence I choose RELU\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    '''\n",
    "    def normalize(x, a, b):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Use a lambda layer to normalize the input data\n",
    "    #model.add(Lambda(lambda x: normalize(x, 0, 1), input_shape=image_shape, output_shape=image_shape))\n",
    "    # Removed Lambda layer. Seems to add more troubles than it helps.\n",
    "    model.add(Convolution2D(nb_filter=24, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2), input_shape=image_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=36, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=48, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Activation('relu'))     \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I want to play with optimizers later, but for the moment, a standard adam should be more than fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    return Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2models = \"./models/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "\n",
    "def train_model(train_gen, val_gen, batch_size, epochs, model, \\\n",
    "                optimizer=None, limit_train=None, limit_val=None):\n",
    "    \n",
    "    if optimizer:\n",
    "        model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\") # This is a nice optimizer to be left as default\n",
    "        \n",
    "    # Callbacks\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(factor=0.5, patience=3, cooldown=3, min_lr=1e-5)\n",
    "    checkpoint = ModelCheckpoint(filepath=path2models)\n",
    "    early_stopping = EarlyStopping(min_delta=2*1e-3, patience=7)\n",
    "    \n",
    "    ls_callbacks = [checkpoint, reduce_lr_on_plateau, early_stopping]\n",
    "    \n",
    "        \n",
    "    samples_per_epoch = limit_train if limit_train else train_gen.get_epoch_size()\n",
    "    nb_epoch = epochs\n",
    "    nb_val_samples = limit_val if limit_val else val_gen.get_epoch_size()\n",
    "    history = model.fit_generator(train_gen, samples_per_epoch, nb_epoch, \\\n",
    "                                  nb_val_samples=nb_val_samples, validation_data=val_gen, callbacks=ls_callbacks)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data with a python generator so we can do data augmentation on the fly\n",
    "\n",
    "class My_dataset_gen():\n",
    "    \"\"\"\n",
    "    To be strict, My_dataset_gen is not a real generator (does not call yield) but an iterator\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 path2csv,\n",
    "                 batch_size,\n",
    "                 crop_input,\n",
    "                 training=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.crop_input = crop_input\n",
    "        \n",
    "        # Load the CSV\n",
    "        self.path2csv = path2csv\n",
    "        df = pd.read_csv(self.path2csv)\n",
    "        self.dataset = df.to_dict(orient='records') # This is a list of dict\n",
    "        \n",
    "        self.position = 0\n",
    "        self.size_epoch = len(self.dataset)\n",
    "        self.training = training\n",
    "        \n",
    "        # Angle-preserving transformations\n",
    "        self.angle_preserving = [data_aug.salt_and_pepper, data_aug.bilateral_filter, data_aug.speckle_noise, \\\n",
    "                               random_light, data_aug.random_shadow, data_aug.identity]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        number_of_samples = 0\n",
    "        X_l = list()\n",
    "        Y_l = list()\n",
    "        \n",
    "        while number_of_samples < self.batch_size:\n",
    "            if self.position == self.size_epoch:\n",
    "                shuffle(self.dataset)\n",
    "                self.position = 0\n",
    "                \n",
    "            sample = self.dataset[self.position]\n",
    "            \n",
    "            rand_val = random.random()\n",
    "            \n",
    "            if not self.training or rand_val <= 1-sample['Probability appearance']: # This way we eliminate biases toward more frequent values\n",
    "                # E.g. sample['Probability appearance'] = 0.25. This means it appears  only 25% of the times in the dataset\n",
    "                # but I want to balance it, so I do 1-0.25= 0.75. Comparing with a random value between 0 and 1, this sample \n",
    "                # will be used (with data augmentation techniques) the 75% of the times. Category samples with a high \n",
    "                # 'Probability appearance' will be more likely rejected, but because of there are more samples of that \n",
    "                # category doesn't matter. On average all categories should be balanced.\n",
    "                image = imread(sample['Updated image path'])\n",
    "                image = self._crop(image)\n",
    "                angle = sample['Steering angle']\n",
    "                \n",
    "                if self.training:\n",
    "                    image, angle = self._random_transform(image, angle)\n",
    "                    \n",
    "                image = self._normalize(image)\n",
    "                \n",
    "                X_l.append(image)\n",
    "                Y_l.append(angle)\n",
    "                \n",
    "                number_of_samples += 1\n",
    "                \n",
    "            self.position += 1\n",
    "            \n",
    "            \n",
    "        X = np.array(X_l) # Current shape follows tf dim_ordering: (samples, height, width, channels)\n",
    "        Y = np.array(Y_l)\n",
    "        \n",
    "        return (X,Y)\n",
    "            \n",
    "    \n",
    "    def _normalize(self, x, a=0, b=1):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    \n",
    "    def _crop(self, x):\n",
    "            return x[50:150, :] # See Explore dataset + Experimental setup.ipynb\n",
    "\n",
    "    def _random_transform(self, image, angle):\n",
    "        # We are always going to choose a random angle-preserving transformation (the identity is included) and\n",
    "        # after that a non-angle-preserving transformation the half of the time.\n",
    "        \n",
    "        # Angle-preserving transformation\n",
    "        image = random.choice(angle_preserving)(image)\n",
    "        \n",
    "        # Non-angle-preserving transformation\n",
    "        \n",
    "        if random.random() >= 0.5:\n",
    "            image = data_aug.horizontal_flipping(image)\n",
    "            angle = -angle\n",
    "    \n",
    "    def get_image_shape(self):\n",
    "        \n",
    "        temp = imread(self.dataset[0]['Updated image path'])\n",
    "        \n",
    "        if self.crop_input:\n",
    "            return self._crop(temp).shape\n",
    "        else:\n",
    "            return temp.shape\n",
    "        \n",
    "    def get_epoch_size(self):\n",
    "        return self.size_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's perform a quick test to see if all the pieces work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path2csv_training = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_training.csv\"\n",
    "path2csv_validation = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_validation.csv\"\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 2\n",
    "limit_train = 10\n",
    "limit_val = 10\n",
    "\n",
    "train_gen = My_dataset_gen(path2csv_training, batch_size, crop_input=True)\n",
    "val_gen = My_dataset_gen(path2csv_validation, batch_size, crop_input=True, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 26050\n",
      "Number of validation samples: 6513\n",
      "Shape of the images:  (100, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some statistics about the dataset\n",
    "\n",
    "print(\"Number of training samples: %d\" % (train_gen.get_epoch_size()))\n",
    "print(\"Number of validation samples: %d\" % (val_gen.get_epoch_size()))\n",
    "print(\"Shape of the images: \", train_gen.get_image_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_16 (Convolution2D) (None, 48, 158, 24)   1824        convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 48, 158, 24)   0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 22, 77, 36)    21636       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 22, 77, 36)    0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 9, 37, 48)     43248       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 9, 37, 48)     0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 7, 35, 64)     27712       activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 7, 35, 64)     0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 5, 33, 64)     36928       activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 5, 33, 64)     0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 10560)         0           activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 1164)          12293004    flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 1164)          0           dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 100)           116500      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 100)           0           dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 50)            5050        activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 50)            0           dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 10)            510         activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 10)            0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 1)             11          activation_36[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 12,546,423\n",
      "Trainable params: 12,546,423\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_nvidia(train_gen.get_image_shape())\n",
    "optimizer = get_optimizer()\n",
    "\n",
    "# Just have a look at our model before training:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 2s - loss: 0.1644 - val_loss: 0.0284\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0240\n"
     ]
    }
   ],
   "source": [
    "history, model = train_model(train_gen, val_gen, batch_size, epochs, model, optimizer, limit_train, limit_val)\n",
    "# There is no need to save the model. It's already saved by the callbacks provided in fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_loss_vs_epochs(training_loss, validation_loss):\n",
    "    plt.plot(range(1,len(training_loss)+1), training_loss, 'b')\n",
    "    plt.xticks(range(1,len(training_loss)+1))\n",
    "    plt.hold(True)\n",
    "    plt.plot(range(1,len(training_loss)+1), validation_loss, 'g')\n",
    "    plt.hold(False)\n",
    "    _ = plt.legend((\"Training\", \"Validation\"), loc='lower right')\n",
    "    _ = plt.ylabel(\"Loss\")\n",
    "    _ = plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAF5CAYAAACiFUGDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xl8FdX9//HXJyFs0gI1CAWKKJZN65KIyFYVVEBx12KE\nqqWKKFSMWsEVQaQqCkoRQbQiUqIoimvFH3zbuoHWRLGVxY2iVaGCSpV9+fz+mHvhZiO5yU3mJvf9\nfDzyIPfMmTNnqCWfzPvMjLk7IiIiImFIC3sCIiIikrpUiIiIiEhoVIiIiIhIaFSIiIiISGhUiIiI\niEhoVIiIiIhIaFSIiIiISGhUiIiIiEhoVIiIiIhIaFSIiIiISGiSphAxs+FmttrMtpjZUjPrso++\nnc3sqUj/3WZ2ZQl90szsNjP71Mw2m9nHZnZT1Z6FiIiIxCMpChEzGwjcA4wBjgKWAQvNLLOUXRoC\nnwCjgK9K6TMauAy4AugIXAdcZ2YjEjh1ERERqQRLhpfemdlS4C13Hxn5bMDnwBR3v6uMfVcDk919\nSpH254G17n5pTNtTwGZ3vzDR5yAiIiLxC/2KiJllANnA4mibB9XRIqBbJYZ+E+hjZj+PHOcIoAfw\nUiXGFBERkQSqE/YEgEwgHVhXpH0d0KES494B/BhYaWa7CIquG9398UqMKSIiIgmUDIVIaQyoTG40\nELgAOB9YDhwJ3GdmX7r7Y8UOZrY/0Bf4N7C1EscVERFJNfWBtsBCd98Qz47JUIisB3YBzYu0H0Dx\nqyTxuAuY4O5PRj5/YGZtgeuBYoUIQRHy50ocT0REJNUNAubGs0PohYi77zCzfKAP8BzsWazaB5iy\nr33L0JDiV1R2U/q6mH8DzJkzh06dOlXisCIiIqllxYoVDB48GCI/S+MReiESMQl4NFKQvA3kEhQS\nswDMbDbwH3e/IfI5A+hMEN/UBVpFFqP+4O6fRMZ8HrjRzD4HPgCyIuM+VMoctgJ06tSJrKyshJ+g\niIhICoh7aUNSFCLuPi/yzJBxBBHNe0Bfd/860qU1sDNml5bAu+y94nFt5OvvQO9I2wjgNuB+gpjn\nS+CBSJuIiIgkgaQoRADcfRowrZRtvYt8XkMZtx67+ybg6siXiIiIJKHQnyMiIiIiqUuFiIiIiIRG\nhYiIiIiERoWIiIiIhEaFiIiIiIRGhYiIiIiERoWIiIiIhEaFiIiIiIRGhYiIiIiERoWIiIiIhEaF\niIiIiIRGhYiIiIiERoWIiIiIhEaFiIiIiIRGhYiIiIiERoWIiIiIhEaFiIiIiIRGhYiIiIiERoWI\niIiIhEaFiIiIiIRGhUgR7mHPQEREJHWoECniyivh44/DnoWIiEhqUCFSxKefwqGHws03w+bNYc9G\nRESkdkuaQsTMhpvZajPbYmZLzazLPvp2NrOnIv13m9mVpfRraWaPmdl6M9tsZsvMLGtf83jqKbju\nOrjrLujcGRYsUFwjIiJSVZKiEDGzgcA9wBjgKGAZsNDMMkvZpSHwCTAK+KqUMZsAbwDbgL5AJ+Aa\n4Nt9zaVBA7jtNvjXv4JC5Kyz4NRTFdeIiIhUhaQoRIBcYIa7z3b3lcAwYDMwpKTO7v6Ou49y93nA\n9lLGHA185u6XuHu+u69x90Xuvro8E/r5z+HFF4MrIsuXK64RERGpCqEXImaWAWQDi6Nt7u7AIqBb\nJYY+DXjHzOaZ2TozKzCzS+KbG5xxRlCIjBqluEZERCTRQi9EgEwgHVhXpH0d0KIS4x4MXA6sAk4G\npgNTzGxwvAM1bAjjxsEHH+yNa045BT76qBKzExERkaQoREpjQGWuO6QB+e5+s7svc/cHgZkExUmF\nHHLI3rhmxQo47DC46SbFNSIiIhVVJ+wJAOuBXUDzIu0HUPwqSTy+AlYUaVsBnL2vnXJzc2ncuHGh\ntpycHHJycoC9cc1JJ8EddwRxzWOPwb33wplnBttFRERqq7y8PPLy8gq1bdy4scLjmSfBYgczWwq8\n5e4jI58N+AyY4u4Ty9h3NTDZ3acUaf8z0Nrdj4tpmwx0cfeeJYyTBeTn5+eTlbXPO3wL+fhjGDkS\nXnoJ+vWDKVOCha4iIiKpoqCggOzsbIBsdy+IZ99kiWYmAUPN7EIz60iwnqMhMAvAzGab2YRoZzPL\nMLMjzOxIoC7QKvK5XcyYk4Fjzex6M2tnZhcAlwBTEznxQw6BF16AZ59VXCMiIhKvpChEIrfhXgOM\nA94FDgf6uvvXkS6tKbxwtWWkX36k/VqggGANSHTMd4CzgBzgn8CNwEh3fzzR8zeD00/fe3fN3XdD\np07wzDO6u0ZERGRfkqIQAXD3ae7e1t0buHu3SCER3dbb3YfEfF7j7mnunl7kq3eRMV9y98PdvaG7\nH+ruf6rKc4jeXfOvfwVXRs4+G/r31901IiIipUmaQqQ2iY1rVq0KipIbb4RNm8KemYiISHJRIVJF\nYuOa0aPhnnuCZ5A8/bTiGhERkSgVIlWsQQMYOzZ4GNphh8E55wRxzYcfhj0zERGR8KkQqSbt2hWO\na37xC8U1IiIiKkSqUUlxTadOimtERCR1qRAJQWxcc/jhimtERCR1qRAJUTSuee45xTUiIpKaVIgk\ngdNOU1wjIiKpSYVIkigprunXT3GNiIjUbipEkkxsXPPhh8EtvzfcoLhGRERqJxUiSSoa19xwA0ya\nFMQ18+crrhERkdpFhUgSa9AAbr01iGuOOALOPVdxjYiI1C4qRGqAdu3g+eeDuOajjxTXiIhI7aFC\npAY57bTg6siNNyquERGR2kGFSA3ToAGMGROsHznyyCCu6ds3eA6JiIhITaNCpIY6+OAgqnn+efj4\n4+BhaIprRESkplEhUsMNGKC4RkREai4VIrWA4hoREampVIjUIiXFNddfr7hGRESSlwqRWig2rrn3\nXujYEZ56SnGNiIgkHxUitVQ0rvngAzjqKDjvPDj5ZFi5MuyZiYiI7KVCpJaLjWs+/TR4od7o0fDD\nD2HPTERERIVIyojGNTfdBPfdF9xd8+STimtERCRcKkRSSP36cMstwd01WVnwq18prhERkXAlTSFi\nZsPNbLWZbTGzpWbWZR99O5vZU5H+u83syjLGvj7Sb1LiZ17zHHQQPPssvPCC4hoREQlXUhQiZjYQ\nuAcYAxwFLAMWmllmKbs0BD4BRgFflTF2F+DSyJgS49RTFdeIiEi4kqIQAXKBGe4+291XAsOAzcCQ\nkjq7+zvuPsrd5wHbSxvUzBoBc4BLgO8SP+2aT3GNiIiEKfRCxMwygGxgcbTN3R1YBHSr5PD3A8+7\n+/9VcpxaT3GNiIiEIfRCBMgE0oF1RdrXAS0qOqiZnQ8cCVxf8amlHsU1IiJSneqEPYF9MKBCP/7M\nrDVwL3CSu++IZ9/c3FwaN25cqC0nJ4ecnJyKTKVGisY1v/41XHVVENf06QNTpwZPaRURkdSVl5dH\nXl5eobaNGzdWeDzzkH/VjUQzm4Fz3P25mPZZQGN3P6uM/VcDk919SkzbGcDTwC6CggaCqy4eaavn\nRU7czLKA/Pz8fLKysip9XrXJiy/ClVfC559Dbi7cfDM0ahT2rEREJFkUFBSQnZ0NkO3uBfHsG3o0\nE7likQ/0ibaZmUU+v1nBYRcBvyCIZo6IfL1DsHD1iKJFiOxbNK65+WaYMiW4KjJvnuIaERGpvNAL\nkYhJwFAzu9DMOgLTCW7RnQVgZrPNbEK0s5llmNkRZnYkUBdoFfncDsDdN7n78tgvYBOwwd1XVPO5\n1Qr16weFyPLlcPTRMHAgnHSS7q4REZHKSYpCJHIb7jXAOOBd4HCgr7t/HenSmsILV1tG+uVH2q8F\nCoCZ+zpMgqedkg46CBYsCOKaf/87uLtm1CjdXSMiIhWTFIUIgLtPc/e27t7A3bu5+zsx23q7+5CY\nz2vcPc3d04t89d7H+L3d/eqqPo9Uccop8K9/BYtaFdeIiEhFJU0hIjVP/frBbb4rVhSOa1Yo/BIR\nkXJSISKV1rat4hoREakYFSKSMNG4ZswYxTUiIlI+KkQkoWLjmi5dgrjmxBMV14iISMlUiEiVaNsW\nnnkGXnoJ1qwJ4prrroPvvw97ZiIikkxUiEiV6t9/b1wTfUT8E08orhERkYAKEaly0bhm+XI45hg4\n/3zFNSIiElAhItUmNq757DPFNSIiokJEQtC/P/zzn3DrrYprRERSnQoRCUX9+nDjjUE807Xr3rhm\n+fKwZyYiItVJhYiE6sAD4emn98Y1RxwBv/+94hoRkVShQkSSQmxcc//9QVzz+OOKa0REajsVIpI0\nisY1OTnQp4/iGhGR2kyFiCSdaFzzl7/A558rrhERqc1UiEjS6tcveBia4hoRkdpLhYgktXr1FNeI\niNRmKkSkRlBcIyJSO6kQkRolGteMHau4RkSkNlAhIjVOvXpwww1BXHPssXvjmg8+CHtmIiISLxUi\nUmMdeCDMn783rjnySLj2WsU1IiI1iQoRqfFi45pp04K4Ji9PcY2ISE2gQkRqhaJxzQUXQO/eimtE\nRJKdChGpVaJxzcsvwxdfKK4REUl2SVOImNlwM1ttZlvMbKmZddlH385m9lSk/24zu7KEPteb2dtm\n9j8zW2dmz5hZ+6o9C0kWffsG764ZNy6Iazp0UFwjIpKMkqIQMbOBwD3AGOAoYBmw0MwyS9mlIfAJ\nMAr4qpQ+vYA/Al2BE4EM4BUza5DAqUsSq1cPrr8eVq6E7t2DuOaEExTXiIgkk6QoRIBcYIa7z3b3\nlcAwYDMwpKTO7v6Ou49y93nA9lL6nOLuj7n7Cnf/J3Ax0AbIrpIzkKTVpg089RQsXAhffaW4RkQk\nmYReiJhZBkFxsDja5u4OLAK6JfBQTQAHvkngmFKDnHwyvP9+ENc88IDiGhGRZBB6IQJkAunAuiLt\n64AWiTiAmRlwL/C6u+stJSksGtesWKG4RkQkGSRDIVIaI7iCkQjTgM7A+QkaT2q4onHNEUfANdfA\n//4X9sxERFJLnbAnAKwHdgHNi7QfQPGrJHEzs6nAKUAvdy9tYeseubm5NG7cuFBbTk4OOTk5lZ2K\nJKFoXDNpEowfH0Q1d98dPDbeLOzZiYgkn7y8PPLy8gq1bdy4scLjmSdBQG5mS4G33H1k5LMBnwFT\n3H1iGfuuBia7+5QStk0FzgCOc/dPyxgnC8jPz88nKyurgmciNdlnn8HVVwfPITnuOJg6FQ47LOxZ\niYgkv4KCArKzswGy3b0gnn2TJZqZBAw1swvNrCMwneAW3VkAZjbbzCZEO5tZhpkdYWZHAnWBVpHP\n7WL6TAMGARcAm8yseeSrfvWdltQkJd1dc/XVimtERKpSUhQikdtwrwHGAe8ChwN93f3rSJfWFF64\n2jLSLz/Sfi1QAMyM6TMM+DHwN+DLmK9fVdV5SO0QjWvGj4cZM4K7a/78Z91dIyJSFZKiEAFw92nu\n3tbdG7h7N3d/J2Zbb3cfEvN5jbunuXt6ka/eMX1K2p7u7rOr+9yk5qlXD0aPDu6u6dkTBg+G448P\nXq4nIiKJkzSFiEgyatMGnnwSXnkF1q5VXCMikmgqRETK4aSTFNeIiFQFFSIi5RSNa1auVFwjIpIo\nKkRE4vSznymuERFJFBUiIhWkuEZEpPJUiIhUQmlxzT//GfbMRERqBhUiIgkQG9esWwdHHQW5uVCJ\npx6LiKQEFSIiCRSNa26/HR58EDp2hDlzFNeIiJRGhYhIgtWtC6NGBXFNr17w618H765RXCMiUpwK\nEZEq8rOfwbx58P/+H/z3v4prRERKokJEpIqdeGIQ10yYADNnKq4REYmlQkSkGtStC9ddF8Q1v/yl\n4hoRkSgVIiLVqHVreOKJIK75+mvFNSIiKkREQnDiibBs2d64pkMHxTUikppUiIiEJDauOe64vXHN\n+++HPTMRkeqjQkQkZEXjmqwsuOoqxTUikhpUiIgkidi45qGHgrjmsccU14hI7aZCRCSJFI1rLrww\nuMtGcY2I1FYqRESSUDSuWbQI1q9XXCMitZcKEZEk1qdPENf84Q+Ka0SkdlIhIpLk6taF3/8+iGuO\nP15xjYjULipERGqI1q3h8ceDuGbDhiCuGTlScY2I1GwqRERqmD594L33grjm4YeDuGb2bMU1IlIz\nqRARqYGKxjUXXRTENcuWhT0zEZH4JE0hYmbDzWy1mW0xs6Vm1mUffTub2VOR/rvN7MrKjilSE5UW\n13z3XdgzExEpn6QoRMxsIHAPMAY4ClgGLDSzzFJ2aQh8AowCvkrQmCI1VjSuueMOxTUiUrMkRSEC\n5AIz3H22u68EhgGbgSEldXb3d9x9lLvPA7YnYkyRmi42rjnhBMU1IlIzhF6ImFkGkA0sjra5uwOL\ngG7JMqZITRGNaxYvVlwjIskv9EIEyATSgXVF2tcBLZJoTJEapXfvIK65807FNSKSvOqEPYF9MCDR\n/2SWOWZubi6NGzcu1JaTk0NOTk6CpyJS9erWhWuvhZyc4M+LLoIHH4T774cjjgh7diJSE+Xl5ZGX\nl1eobWMlHmiUDIXIemAX0LxI+wEUv6JR5WNOnjyZrKysCh5WJDm1agV5eTB0KAwfHsQ1w4fDuHHQ\npEnYsxORmqSkX84LCgrIzs6u0HihRzPuvgPIB/pE28zMIp/fTJYxRWqDE04IFq/eeSc88kgQ1zz6\nKOzeHfbMRCRVhV6IREwChprZhWbWEZhOcIvuLAAzm21mE6KdzSzDzI4wsyOBukCryOd25R1TJFVl\nZAQxzcqVwTqSiy/W3TUiEp6kKEQit+FeA4wD3gUOB/q6+9eRLq0pvMi0ZaRffqT9WqAAmBnHmCIp\nLRrX/N//wTffBHHNlVfq7hoRqV7mWkIPgJllAfn5+flaIyIpZ8cOmDIFbr0VGjaEu+6CX/8a0pLi\nVxURSXYxa0Sy3b0gnn0r9M+MmfUzs54xn4eb2XtmNtfMmlZkTBEJT0YGXHNNENf06aO4RkSqT0V/\n35kI/BjAzH5B8Cj1l4CDCNZmiEgN1KoVzJ0bxDXffqu4RkSqXkULkYOA5ZHvzwFecPcbgOFA/0RM\nTETCc8IJwcPQ7rpLd9eISNWqaCGyneAOFIATgVci339D5EqJiNRs0bhm1aq9cU2vXkGBIiKSKBUt\nRF4HJpnZzcAxwIuR9vbAfxIxMRFJDi1bBnHNX/8aRDTZ2fC73ymuEZHEqGghMgLYCZwLXO7uX0Ta\n+wMvJ2JiIpJcjj8+uBoycSLMmgXt2wd/Kq4RkcqoUCHi7p+5+wB3P8LdH45pz3X3KxM3PRFJJhkZ\ncPXVQVxz0knwm99Az57w7rthz0xEaqqK3r6bFblbJvr5DDNbYGYTzKxu4qYnIsmoZUv485+DuGbj\nRjj6aBgxIrjTRkQkHhWNZmYQrAfBzA4GHgc2A+cBdyVmaiKS7GLjmkcfDe6uUVwjIvGoaCHSHoiu\nnT8PeNXdLwAuJridV0RShOIaEamMihYiFrPviQQPMwP4HMis7KREpOaJjWv+9z/FNSJSPhUtRN4B\nbjKzXwPHsff23YOAdYmYmIjUTMcfH1wNmTgRZs8O4ppHHlFcIyIlq2ghchWQBUwFbnf3jyPt5wJv\nJmJiIlJzReOalSuDuGbIEMU1IlKyit6++767/8LdG7v72JhNvwcuSszURKSmi8Y1f/ub4hoRKVml\nXvJtZtlmNtjMBplZlrtvdfcdiZqciNQOxx0XXA25+27FNSJSWEWfI3KAmf0V+AcwhSCiecfMFptZ\ns0ROUERqh4wMyM0N7q45+eQgrunRAwoKwp6ZiISpoldE/gj8CDjU3X/i7k2BwwheeDclUZMTkdrn\npz+FOXOCuOb776FLFxg+XHGNSKqqaCHSj+AdMyuiDe6+HBhO8L4ZEZF9io1rHnsseHeN4hqR1FPR\nQiQNKGktyI5KjCkiKSY2runbV3GNSCqqaNHwf8B9ZtYy2mBmrYDJkW0iIuUWG9f88IPiGpFUUtFC\nZATBGpF/m9knZvYxsBpoFNkmIhK3444Lrobcc8/euOZPf1JcI1KbVfQ5Ip+7exZwKnAvwQLVU4Az\ngVsSNz0RSTUZGXDVVUFc068f/Pa3imtEarNKredw9//n7n909ynuvgjYH/htYqYmIqnspz8Nror8\n/e9BXHP00YprRGqjpFlYambDzWy1mW0xs6Vm1qWM/ueZ2YpI/2Vm1r/I9v3MbKqZfW5mm83sAzO7\nrGrPQkQS7Ze/DK6GTJqkuEakNkqKQsTMBgL3AGOAo4BlwEIzK/FNvmbWDZgLzASOBBYAC8ysc0y3\nycDJwAVAR4IIaaqZDaiq8xCRqlFSXNO9u+IakdogKQoRIBeY4e6z3X0lMAzYDAwppf9I4C/uPsnd\nV7n7GKCAwgtluwGPuvtr7v6Zu88kKHCOqbrTEJGqFBvXbNoUxDVXXAHffBP2zESkourE09nMni6j\nS5N4J2BmGUA2MCHa5u5uZosIiomSdCO4ghJrIXBGzOc3gdPN7BF3/9LMTgB+HuknIjVYNK65/364\n5RZ48km44w74zW8gLVl+vRKRcon3/7Iby/haA8yOc8xMIB1YV6R9HdCilH1alKP/74AVwH/MbDvw\nEjDc3d+Ic34ikoSKxjWXXKK4RqQmiuuKiLv/pqomUgIDvBL9rwS6AgOAz4BfAtPM7Et310PXRGqJ\naFxz6aUwYkQQ1wwbBuPHw09+EvbsRKQscRUiVWQ9sAtoXqT9AIpf9Yhau6/+ZlYfuB04w91fjmz/\nl5kdBVzLPp7+mpubS+PGjQu15eTkkJOTU/aZiEhoFNeIVI+8vDzy8vIKtW3cuLHC45l7PBcdqoaZ\nLQXecveRkc9GcBVjirtPLKH/40ADdz8jpu0NYJm7X2FmPyKIivq7+8KYPtOBtu7er4Qxs4D8/Px8\nsrKyEnyGIlKd1q6F664LrpR07RoUJ9nZYc9KpPYqKCggO/g/Wba7xxWQJsvvCZOAoWZ2oZl1BKYD\nDYFZAGY228wmxPS/D+hvZlebWQczu5VgwetUAHf/Hvg7MNHMjjOztmZ2MXAhUNaCWxGp4Vq0gNmz\n4dVXYfPm4N01l1+uu2tEklFSFCLuPg+4BhgHvAscDvR1968jXVoTsxDV3ZcAOcBQ4D3gbIIYZnnM\nsAOBfwBzgA+A64Dr3f3Bqj0bEUkWvXoFcc3kyTB3bvAwtIce0sPQRJJJUkQzyUDRjEjtprhGpOrU\nhmhGRKRKKa4RSU4qREQkpSiuEUkuKkREJOXUqQMjRwYPQzvllOAZJN27Q35+2DMTST0qREQkZSmu\nEQmfChERSXnRuObeexXXiFQ3FSIiIgRxzZVXBnHNqacGcU23bvDOO2HPTKR2UyEiIhKjRQt49FF4\n7TXYuhWOOSZ4d82GDWHPTKR2UiEiIlKCnj2Dxav33Qd5edChA8ycqbhGJNFUiIiIlKJOHfjd7+DD\nD2HAABg6VHGNSKKpEBERKUPz5jBrFrz+OmzbprhGJJFUiIiIlFOPHsHVkGhc07694hqRylIhIiIS\nh9i45rTTFNeIVJYKERGRClBcI5IYKkRERCohNq55/HHFNSLxUiEiIlJJ0bhm1aq9cc2xx8I//hH2\nzESSnwoREZEEiY1rtm+Hrl3hsssU14jsiwoREZEEi8Y1U6bAE08Ecc2DD8KuXWHPTCT5qBAREakC\nderAiBFBXHP66cGVEcU1IsWpEBERqULNm8Mjj8Abb8DOnUFcM3QorF8f9sxEkoMKERGRatC9e3A1\nZMoUmDcveHeN4hoRFSIiItVGcY1IcSpERESqmeIakb1UiIiIhKSkuGbGDMU1klpUiIiIhCga13z4\nYRDXDBsWxDVvvx32zESqR9IUImY23MxWm9kWM1tqZl3K6H+ema2I9F9mZv1L6NPJzJ41s+/M7Acz\ne8vMWlfdWYiIVMwBBxSOa449VnGNpIakKETMbCBwDzAGOApYBiw0s8xS+ncD5gIzgSOBBcACM+sc\n06cd8BqwHPgl8AvgNmBr1Z2JiEjldO8ePAztj39UXCOpISkKESAXmOHus919JTAM2AwMKaX/SOAv\n7j7J3Ve5+xigABgR02c88KK7X+/u77v7and/wd31+4WIJLX0dBg+PIhrzjgjiGu6dlVcI7VT6IWI\nmWUA2cDiaJu7O7AI6FbKbt0i22MtjPY3MwNOBT4ys5fNbF0k7jkj0fMXEakqBxwAf/oTvPlmcEXk\n2GPh0ksV10jtEnohAmQC6cC6Iu3rgBal7NOijP4HAI2AUcBLwEnAM8DTZtYrAXMWEak23brtjWue\neip4d43iGqkt6oQ9gX0wwCvYP1pgLXD3KZHv3zez7gSxz2ulDZKbm0vjxo0LteXk5JCTkxPHVERE\nEisa15x3HoweHcQ1M2fCtGlwzDFhz05SSV5eHnl5eYXaNm7cWOHxkqEQWQ/sApoXaT+A4lc9otaW\n0X89sBNYUaTPCqDHviYzefJksrKyypiyiEg4onHNpZfCFVcEcc1vfwt/+ANklri8XySxSvrlvKCg\ngOzs7AqNF3o04+47gHygT7QtssajD/BmKbstie0fcVKkPTrmP4AORfq0B9ZUftYiIuGKxjVTp+6N\na6ZPV1wjNU/ohUjEJGComV1oZh2B6UBDYBaAmc02swkx/e8D+pvZ1WbWwcxuJVjwOjWmz0RgoJld\nYmbtzGwEMAC4v+pPR0Sk6qWnB1dFVq2Cs86Cyy8P7q55662wZyZSfklRiLj7POAaYBzwLnA40Nfd\nv450aU3MwlV3XwLkAEOB94CzgTPcfXlMnwUE60GuA94nuBX47Mi+IiK1xgEHwMMPB3fX7N6tu2uk\nZrHgTlkxsywgPz8/X2tERKTG2rUruKPmxhvBDCZMCIqS9PSwZya1WcwakWx3L4hn36S4IiIiIokR\njWs+/HBvXHPMMYprJHmpEBERqYWaNdsb17gHcc0ll8DXX5e9r0h1UiEiIlKLdesG//hH8LyR+fOD\nd9c88IDurpHkoUJERKSWS08PIpoPP4Szzw6iG8U1kixUiIiIpIhmzeChhxTXSHJRISIikmIU10gy\nUSEiIpKCSotrli4Ne2aSalSIiIiksGhcsyTyqMdu3YJ31yiukeqiQkRERDj2WHj77SCueeaZ4N01\n06YprpEmzJA9AAAcDElEQVSqp0JERESAvXHNqlVwzjkwfLjiGql6KkRERKQQxTVSnVSIiIhIiaJx\nzQMPKK6RqqNCRERESpWeDsOGBXfXnHuu4hpJPBUiIiJSpsxMmDlTcY0kngoREREpN8U1kmgqRERE\nJC4lxTVduuy9WiISDxUiIiJSIdG4ZulSSEuD7t1hyBD473/DnpnUJCpERESkUrp2Dd7kO306LFgQ\nvLvm/vsV10j5qBAREZFKS0+Hyy4L4przzoPf/U5xjZSPChEREUmYzEx48MEgrklPV1wjZVMhIiIi\nCRd91sj06fDss4prpHQqREREpEpE45pVqxTXSOlUiIiISJVSXCP7kjSFiJkNN7PVZrbFzJaaWZcy\n+p9nZisi/ZeZWf999J1hZrvN7MrEz1xERMpDcY2UJCkKETMbCNwDjAGOApYBC80ss5T+3YC5wEzg\nSGABsMDMOpfQ90zgGOCLqpm9iIiUV0lxzdFHw5tvhj0zCUtSFCJALjDD3We7+0pgGLAZGFJK/5HA\nX9x9kruvcvcxQAEwIraTmbUCpgAXADurbPYiIhKX2LimTh3o0QN+8xvFNako9ELEzDKAbGBxtM3d\nHVgEdCtlt26R7bEWxvY3MwNmA3e5+4pEzllERBIjGtfMmAHPPRe8u2bqVNipXx1TRuiFCJAJpAPr\nirSvA1qUsk+LcvQfDWx396mJmKSIiFSN9HQYOjR4GNrAgXDllUFc88YbYc9MqkMyFCKlMcAr0t/M\nsoErgd9UwbxERKQK7L9/cGXkrbcgIwN69oSLL4Z1RX/tlFqlTtgTANYDu4DmRdoPoPhVj6i1ZfTv\nCTQDPg8SGiC46jLJzK5y94NLm0xubi6NGzcu1JaTk0NOTk4ZpyEiIonQpUsQ1zz8MFx/ffD+mvHj\ngzf+1kmGn1opLi8vj7y8vEJtGzdurPB4FizHCJeZLQXecveRkc8GfAZMcfeJJfR/HGjg7mfEtL0B\nLHP3K8ysKfDTIru9QrBm5BF3/6iEMbOA/Pz8fLKyshJ1aiIiUgkbNsANNwRv+T388OB23x49wp6V\nFFVQUEB2djZAtrsXxLNvstSWk4BHzSwfeJvgLpqGwCwAM5sN/Mfdb4j0vw/4u5ldDbwI5BAseL0U\nwN2/Bb6NPYCZ7QDWllSEiIikis8++4z169eHPY24XHZZENP84Q/BnwMGBOtI9t8/7JmllszMTNq0\naZPwcZOiEHH3eZFnhowjiFzeA/q6+9eRLq2Juf3W3ZeYWQ5we+TrI+AMd1++r8NUyeRFRGqIzz77\njE6dOrF58+awp1IpL7wQfEn1atiwIStWrEh4MZIUhQiAu08DppWyrXcJbfOB+XGMX+q6EBGRVLB+\n/Xo2b97MnDlz6NSpU9jTkRpkxYoVDB48mPXr19feQkRERKpHp06dtBZOkkYy374rIiIitZwKERER\nEQmNChEREREJjQoRERERCY0KERERkTisWrWKtLQ05s2bF/e+27ZtIy0tjbvuuqsKZlYzqRAREZEa\nLS0trcyv9PR0Xn311YQdM+b1IRXatzL71za6fVdERGq0OXPmFPr86KOPsmjRIubMmUPsa0wS9eyU\nDh06sGXLFurWrRv3vvXq1WPLli1kZGQkZC61gQoRERGp0S644IJCn5csWcKiRYvK/bLSrVu3Ur9+\n/biOWZEiJBH71kaKZkREJGUsXLiQtLQ0nnnmGUaNGkWrVq1o1KgR27dvZ/369eTm5nLYYYfRqFEj\nmjRpwmmnncby5YXfHlLSGpHzzz+fZs2a8fnnnzNgwAB+9KMf0bx5c2688cZC+5a0RmT06NGkpaXx\n+eefM3jwYJo0acJPfvITLrvsMrZv315o/82bN3PFFVew//778+Mf/5hzzz2XNWvW1Oh1J7oiIiIi\nKefmm29mv/32Y9SoUWzatIn09HRWrVrFyy+/zLnnnsuBBx7IV199xfTp0zn++ONZvnw5mZmZpY5n\nZuzYsYOTTjqJ448/nrvvvpuXX36ZO+64g/bt23PRRRftc18z48wzz6R9+/bceeedvP322zz00EO0\nbNmSMWPG7Ombk5PDCy+8wJAhQ8jOzmbRokWceeaZNXrNiQoREREp0ebNsHJl1R6jY0do2LBqj1ES\nd+eNN96gTp29Pwa7dOnCihUrCvXLycnh0EMP5dFHH+Waa67Z55jff/89t9xyC1dffTUAl112GYcd\ndhgPP/zwPguR6Hx69OjBlClT9uy7du1aHn744T2FyJIlS3j++ee54YYbGD9+PADDhg3jggsu4P33\n34/vLyCJqBAREZESrVwJ2dlVe4z8fAjjtTdDhgwpVIRA4bUbu3btYuPGjTRp0oSDDjqIgoKCco07\ndOjQQp979uzJC+V4VbCZcdlllxVq69WrFwsXLmTHjh1kZGTw8ssvY2Zcfvnlhfr97ne/4/HHHy/X\n/JKRCpEitu/czq7du0iztBp9qUtEpLI6dgwKhao+Rhjatm1brG337t3cfffdzJgxgzVr1rB7924g\nKBIOOeSQMsds0qQJjRo1KtTWtGlTvv3223LNqehbbZs2bYq7891339GsWTPWrFlDvXr1aNWqVaF+\n5ZlbMlMhUkS3h7vBX4Lv66TVKfErIy2j1G17+qSX0cfK2a+cx0vkWCrARASCyKS2vqS3QYMGxdpu\nueUWJkyYwLBhwzjhhBNo2rQpaWlpXH755XuKkn1JT08vsT32FuKq3L+mUiFSxLgTxtG6Q2t27t5Z\n4teO3TtK3bavPpt3bC7eb1f8Y+32sv/PUFlplpaYYiuewq2ai62Sxkoz3UQmksrmz5/PKaecwrRp\n0wq1f/PNN7Rr1y6kWe114IEHsm3bNr744otCV0U++uijEGdVeSpEiji1/alkHZW8vwLs9t3s2r2r\nYgVSOQqfSo3lxftt27mNTbs3Vfp4O3fvrPK/W8NqfbFV0le6pesqmKSU0v57T09PL3b14bHHHmPD\nhg3VMa0y9e3bl9tuu41p06Zx++2372n/4x//WKP/P6xCpIZJszTS0tPISE+tp/K5O7u8eAFW7cVW\nHGNt3bk17mKr6DF37N5RLX+/CSu2Sip8LPxiq7SxavI/3lJxpUUdAwYMYOLEiQwdOpQuXbqwbNky\nnnjiiRLXk4She/funHrqqdxxxx2sXbuWo48+msWLF7N69Wqgco+dD5MKEakRzGzPD7RUs9t3J22x\nVVKfkmLIeI+5Y/eOaoshE1Js1ZCrZNt3bi/7L6WW2NcP5dK23XrrrWzbto158+aRl5dHly5deOWV\nVxg+fHixfUoao7RxS9q3POOV5IknnuDaa6/liSeeYP78+fTr1485c+Zw6KGHxv102GRhtX0RTHmZ\nWRaQn5+fT1ZtXZ0lUoOUFkOGWmxFxyohhqxIsVXatirzJfAg6N+52mXp0qV0796d+fPnc9ZZZ1XJ\nMQoKCsjOzi71v53odiDb3ct3r3NE6v16KSI1QirHkLFXwRJZbH30wUeMeXBM2ZOQpLVt2zbq1atX\nqO2+++6jTp069OzZM6RZVY4KERGRJGJmpFs66Wnp1KNe2TvEoWBHAWNQIVKTjRs3jpUrV/LLX/4S\nM+OFF15g8eLFjBw5kmbNmlX58a96+Sr2/2j/YrHfd59+V+ExVYiIiIjUED179uRvf/sb48aNY9Om\nTRx44IHcfvvtjBo1qlqOb2Zs37W92Fqw7zaoEBEREan1+vfvT//+/UM7/uS+k0tfI3J7xd4HkDRP\ncDKz4Wa22sy2mNlSM+tSRv/zzGxFpP8yM+sfs62Omd1pZu+b2Q9m9oWZPWpmP636MxEREZHySopC\nxMwGAvcAY4CjgGXAQjMr8Z3LZtYNmAvMBI4EFgALzKxzpEvDSPvYyHhnAR2AZ6vwNERERCROSVGI\nALnADHef7e4rgWHAZmBIKf1HAn9x90nuvsrdxwAFwAgAd/+fu/d19/nu/pG7vx3Zlm1mrav+dERE\nRKQ8Qi9EzCwDyAYWR9s8eLjJIqBbKbt1i2yPtXAf/QGaAA5UfEWNiIiIJFTohQiQCaQD64q0rwNa\nlLJPi3j6m1k94A5grrv/UPGpioiISCIl810zRnAFo1L9zawO8GRk2xVlDZKbm0vjxo0LteXk5JCT\nkxPHVERERGqnvLw88vLyCrVt3LixwuMlQyGyHtgFNC/SfgDFr3pErS1P/5gi5GdA7/JcDZk8ueRb\nk0RERKTkX85jHvEet9CjGXffAeQDfaJtFrz9pw/wZim7LYntH3FSpD06RrQIORjo4+7fJnDaIiJS\ny7Vu3ZqhQ4fu+bx48WLS0tJ4883SfjTt1bNnT04++eSEzuemm24iI6P2vfIg9EIkYhIw1MwuNLOO\nwHSCW3BnAZjZbDObENP/PqC/mV1tZh3M7FaCBa9TI/3TgflAFjAYyDCz5pGv2ve/oohICjv99NPZ\nb7/92LRpU6l9Bg0aRL169fj22/L/ThrPG3Yr2q+oTZs2MXbsWF5//fUSx0xLS5Yf24mTFGfk7vOA\na4BxwLvA4UBfd/860qU1MQtR3X0JkAMMBd4DzgbOcPflMf0HRP58j+Cdk19F/tzXnTUiIlLDDB48\nmK1bt/LMM8+UuH3Lli0899xznHLKKTRt2rTCx+nTpw9btmyhe/fuFR6jLD/88ANjx47l1VdfLbZt\n7Nix/PBD7bvfIhnWiADg7tOAaaVs611C23yCqx4l9V9DcCeOiIjUcqeffjqNGjVi7ty5DB48uNj2\nBQsWsHnzZgYNGlTpY9WtW7fSY+xL8PSKkqWlpemKiIiISLKpX78+Z599NosWLWL9+vXFts+dO5dG\njRpx2mmnAXDnnXfSo0cP9t9/fxo2bEiXLl1YsGBBmccpbY3IAw88QLt27WjYsCHdunUrcQ3Jtm3b\nuPnmm8nOzqZJkyY0atSI448/ntdee21Pn08++YSWLVtiZtx00017Co8JE4KVCSWtEdm5cydjx46l\nXbt21K9fn4MPPphbbrmFHTt2FOrXunVrzj77bF599VWOOeYYGjRowCGHHMLcuXPLPO+qpkJERERq\nvEGDBrFz507mzZtXqP3bb7/llVde4ZxzzqFevXoATJkyhezsbMaPH88f/vAH0tLSOOecc3jllVfK\nPE7RtR8zZsxg+PDh/OxnP2PixIl069aN0047jS+//LJQv++++45Zs2bRp08f7rrrLm699VbWrl3L\nySefzAcffABAixYtuP/++3F3zjvvPObMmcOcOXM488wz9xy76PEvvvhixo4dS9euXZk8eTK9evVi\n/Pjxxa4MmRmrVq3i/PPPp1+/fkyaNInGjRtz0UUX8dFHH5Xjb7gKubu+gkthWYDn5+e7iEhtlJ+f\n77X137ldu3Z5y5YtvUePHoXap0+f7mlpab5o0aI9bVu3bi3UZ8eOHd65c2fv169fofbWrVv7pZde\nuufzokWLPC0tzd944w13d9++fbtnZmb6Mccc4zt37ix0TDPzk046qdD8duzYUWj87777zps1a+bD\nhg3b07Z27Vo3M7/99tuLneNNN93kGRkZez7n5+e7mfkVV1xRqF9ubq6npaX566+/Xuhc0tLSfOnS\npYWOVbduXb/++uuLHauosv7biW4HsjzOn79Js0ZERESSy+Ydm1m5fmWVHqNjZkcaZjSs9DhpaWmc\nf/753HvvvaxZs4YDDzwQCGKZ5s2b07v33qWG0SsjEFyp2LlzJz179ixXPBPrrbfeYsOGDUycOJH0\n9L3LEocMGcJ1111XbH7R9R3uznfffceuXbs4+uijKSgoiPt8AV566SXMjKuvvrpQ+zXXXMO9997L\niy++SI8ePfa0H3744XTt2nXP5+bNm/Pzn/+cTz/9tELHTxQVIiIiUqKV61eS/WDFHlJVXvlD88n6\naWIeIjlo0CAmT55MXl4eo0eP5osvvuD111/nqquuKhRpPPfcc0yYMIFly5axbdu2Pe3xLkRds2YN\nZsYhhxxSqD0jI4O2bdsW6//II48wefJkVq1aVWgNR/v27eM6buzx69SpQ7t27Qq1t2rVih/96Ees\nWbOmUHubNm2KjdG0adO4bmmuCipERESkRB0zO5I/NL/Kj5EoWVlZdOzYkblz5zJ69Og9CzEvuOCC\nPX3++te/ctZZZ9G7d2+mT59OixYtyMjIYObMmcyfX+KNmKXyyB0uJT0zJLotatasWfz2t7/l3HPP\nZfTo0TRr1oz09HRuu+02vvjii3hPtcRjlLUt9qpNecepDipERESkRA0zGibsakV1GTRoELfccgv/\n/Oc/ycvL4+c//3mhR48//fTT7Lfffrz88suFfjDPmDEj7mO1bdsWd+fDDz8sFIHs2LGDNWvW0KLF\n3vewzp8/nw4dOhRbTHvDDTcU+hzPg9Datm3Lzp07+eSTTwpdFfnyyy/54Ycf9sRTyU53zYiISK0x\naNAg3J1bbrmF9957r9jdI+np6aSlpbFr1649bZ9++inPP/983Mfq2rUrP/nJT5g+fXqh8R566CG+\n//77Ysct6o033uAf//hHobb99tsPCNaulOWUU07B3bn33nsLtd9zzz2YGaeeemq5zyVMuiIiIiK1\nRtu2benevTvPPvssZlYolgEYMGAAU6ZMoW/fvuTk5PDVV18xbdo0OnTosOc22n2JjTEyMjK47bbb\nGDFiBCeccAIDBw7k448/Zvbs2Rx00EHFjvvcc89x9tln079/fz755BMefPBBOnfuXGidyn777Uf7\n9u3Jy8vj4IMPpmnTphx++OF06tSp2FyysrIYNGgQ06ZNY8OGDfTq1YslS5YwZ84cfvWrXxW6SpPM\ndEVERERqlUGDBmFmdO3alYMPPrjQthNPPJGZM2fy5ZdfctVVV/Hkk09yzz33MGDAgGLjlPTcjqKf\nL7/8cqZOncoXX3zB73//e9566y1eeOEFWrVqVajvJZdcwvjx43n33Xe56qqrWLx4MXl5eRx55JHF\nxvzTn/5EixYtyM3N5YILLij06PqifWfNmsWYMWN46623yM3N5bXXXuPmm29mzpw5ZZ5LaWNWNwt7\nkUqyMLMsID8/P5+srJqViYqIlEf0Ve36d07iVdZ/O9HtQLa7x3U/sq6IiIiISGhUiIiIiEhoVIiI\niIhIaFSIiIiISGhUiIiIiEhoVIiIiIhIaFSIiIiISGhUiIiIiEho9Ih3EZEUs2LFirCnIDVM9L+Z\n66+HP/0JWrVK3NgqREREUkRmZiYNGzYs9iI4kfKoV68h+fmZdOwIY8bAyJGQkVH5cVWIiIikiDZt\n2rBixQrWr18f9lSkBsrMzOTHP27DmDEwalRwZWTqVOjdu3LjqhAREUkhbdq0oU2bNmFPQ2qw++6D\nIUNgxAjo0wcGDoSLL674eEmzWNXMhpvZajPbYmZLzaxLGf3PM7MVkf7LzKx/CX3GmdmXZrbZzP6f\nmR1SdWcgIiKSGo44Al59FWbPhr/9Dc4+u+JjJUUhYmYDgXuAMcBRwDJgoZllltK/GzAXmAkcCSwA\nFphZ55g+o4ARwGXAMcCmyJh1q/BUREREUoIZ/PrXsGoVnHlmxcdJikIEyAVmuPtsd18JDAM2A0NK\n6T8S+Iu7T3L3Ve4+BiggKDxi+9zm7s+7+7+AC4GWQCX+ukRERCRW48Zw7bUV3z/0QsTMMoBsYHG0\nzd0dWAR0K2W3bpHtsRZG+5vZwUCLImP+D3hrH2OKiIhINQu9EAEygXRgXZH2dQTFRElalNG/OeBx\njikiIiLVLJnvmjGCYiKR/ffVpz7oQT8iIiLxivnZWT/efZOhEFkP7CK4ihHrAIpf0YhaW0b/tQRF\nR/MiYxwAvFvKmG0BPehHRESk4toCb8azQ+iFiLvvMLN8oA/wHICZWeTzlFJ2W1LC9pMi7bj7ajNb\nG+nzfmTMHwNdgftLGXMhMAj4N7C14mckIiKScuoTFCEL493RgnWh4TKzXwGPEtxq+zbBXTTnAh3d\n/Wszmw38x91viPTvBvwdGA28COREvs9y9+WRPtcBo4CLCYqL24BDgUPdfXu1nZyIiIiUKvQrIgDu\nPi/yzJBxBHHKe0Bfd/860qU1sDOm/xIzywFuj3x9BJwRLUIife4ys4bADKAJ8BrQX0WIiIhI8kiK\nKyIiIiKSmpLh9l0RERFJUSpEREREJDQpX4iYWS8ze87MvjCz3WZ2ethzEhERqQnM7Hoze9vM/mdm\n68zsGTNrH88YKV+IAPsRLI4dTnwPUBMREUl1vYA/Ejwe40QgA3jFzBqUdwAtVo1hZruBM939ubDn\nIiIiUtNE7oD9L/BLd3+9PPvoioiIiIgkShOCdOGb8u6gQkREREQqLfJU9HuB12Of61WWpHigmYiI\niNR404DOQI94dlIhIiIiIpViZlOBU4Be7v5VPPuqEBEREZEKixQhZwDHuftn8e6f8oWIme0HHAJY\npOlgMzsC+MbdPw9vZiIiIsnNzKYRvHj2dGCTmTWPbNro7uV6k33K375rZscBf6X4M0QedfchIUxJ\nRESkRog89qKkQuI37j67XGOkeiEiIiIi4dHtuyIiIhIaFSIiIiISGhUiIiIiEhoVIiIiIhIaFSIi\nIiISGhUiIiIiEhoVIiIiIhIaFSIiIiISGhUiIiIiEhoVIiJSq5jZbjM7Pex5iEj5qBARkYQxs0ci\nhcCuyJ/R718Ke24ikpxS/u27IpJwfwEuZu8brQG2hTMVEUl2uiIiIom2zd2/dvf/xnxthD2xyTAz\ne8nMNpvZJ2Z2TuzOZnaYmS2ObF9vZjPMbL8ifYaY2b/MbKuZfWFmU4rMoZmZPW1mm8zsQzM7LWbf\nJmb2ZzP7b+QYq8zsoir72xCRfVIhIiLVbRzwJHA48GfgcTPrAGBmDYCXgQ1ANnAucCLwx+jOZnY5\nMBWYDhwGnA58XOQYtwCPA78AXgL+bGZNItvGAx2BvpE/LwfWJ/okRaR8zN3DnoOI1BJm9ggwGNga\n0+zABHe/w8x2A9PcfUTMPkuAfHcfYWaXAn8AWrv71sj2/sDzwE/d/Wsz+w/wsLuPKWUOu4Fx7n5r\n5HND4Hugv7u/YmbPAl+7+yWJPXsRqQitERGRRPs/YBiF14h8E/P90iL9lwBHRL7vCCyLFiERbxBc\nve1gZgAtI8fYl39Gv3H3zWb2PXBApOkBYL6ZZQOvAAvcfUlZJyUiVUOFiIgk2iZ3Xx3nPtFLsxbz\nfUl9tpRzvB0l7JsG4O4vm1kb4FSC2GexmU119+vim7KIJILWiIhIdTu2hM8rI98vB46MrBWJ6gns\nAla5+w/Av4E+lZmAu29w99nufiFwFTC0MuOJSMXpioiIJFo9M2tepG2nu2+IfH+emeUDrxOsJ+kC\nDIls+zNwK/ComY0liFOmALPdPbqg9FbgATP7muBW4R8D3d19ankmFxk3H/gAqA8MICiARCQEKkRE\nJNH6AV8WaVsFdI58PwY4H7gf+Ao4391XArj7FjPrC9wHvA1sBp4CrokO5O6zzawekAtMJLjj5amY\nY5UU7XhM+3ZgAtCWIOp5DcipwHmKSALorhkRqTaRO1rOdPfnwp6LiCQHrRERERGR0KgQEZHqpEuw\nIlKIohkREREJja6IiIiISGhUiIiIiEhoVIiIiIhIaFSIiIiISGhUiIiIiEhoVIiIiIhIaFSIiIiI\nSGhUiIiIiEho/j94Hj+iXDHwSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46b8041588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_vs_epochs(history.history['loss'], history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do the real training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = My_dataset_gen(path2csv_training, batch_size, crop_input=True)\n",
    "val_gen = My_dataset_gen(path2csv_validation, batch_size, crop_input=True, training=False)\n",
    "\n",
    "model = get_model_nvidia(train_gen.get_image_shape())\n",
    "optimizer = get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history, model = train_model(train_gen, val_gen, batch_size, epochs, model, optimizer)\n",
    "# There is no need to save the model. It's already saved by the callbacks provided in fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_vs_epochs(history.history['loss'], history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-TensorFlow-Lab]",
   "language": "python",
   "name": "conda-env-CarND-TensorFlow-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
