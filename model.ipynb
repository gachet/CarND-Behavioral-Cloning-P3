{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything at the begining (My past as a C/C++ programmer betrays me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy.misc import imread\n",
    "from random import shuffle\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an initial model. I don't agree to much with the idea of doing subsampling (stride>1) in the convolutional layers, as I read in multiple places that is more destructive than using a pooling layer after the convolutional one without subsampling, but let's give it an oportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_nvidia(image_shape):\n",
    "    \"\"\"\n",
    "    End to End Learning for Self-Driving Cars\n",
    "    http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "    \n",
    "    No info is provided for activations, hence I choose RELU\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    '''\n",
    "    def normalize(x, a, b):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Use a lambda layer to normalize the input data\n",
    "    #model.add(Lambda(lambda x: normalize(x, 0, 1), input_shape=image_shape, output_shape=image_shape))\n",
    "    # Removed Lambda layer. Seems to add more troubles than it helps.\n",
    "    model.add(Convolution2D(nb_filter=24, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2), input_shape=image_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=36, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=48, nb_row=5, nb_col=5, border_mode='valid', subsample=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filter=64, nb_row=3, nb_col=3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Activation('relu'))     \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I want to play with optimizers later, but for the moment, a standard adam should be more than fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    return Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2models = \"./models/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "\n",
    "def train_model(train_gen, val_gen, batch_size, epochs, model, \\\n",
    "                optimizer=None, limit_train=None, limit_val=None, parallel=None):\n",
    "    \n",
    "    if optimizer:\n",
    "        model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\") # This is a nice optimizer to be left as default\n",
    "        \n",
    "    # Callbacks\n",
    "    reduce_lr_on_plateau = ReduceLROnPlateau(factor=0.5, patience=3, cooldown=3, min_lr=1e-5)\n",
    "    checkpoint = ModelCheckpoint(filepath=path2models)\n",
    "    early_stopping = EarlyStopping(min_delta=2*1e-3, patience=7)\n",
    "    \n",
    "    ls_callbacks = [checkpoint, reduce_lr_on_plateau, early_stopping]\n",
    "    \n",
    "        \n",
    "    samples_per_epoch = limit_train if limit_train else train_gen.get_epoch_size()\n",
    "    nb_epoch = epochs\n",
    "    nb_val_samples = limit_val if limit_val else val_gen.get_epoch_size()\n",
    "    nb_worker = 1 if parallel is None else multiprocessing.cpu_count() # t2.medum instance has 2 CPU threads, p2.xlarge has 4\n",
    "    history = model.fit_generator(train_gen, samples_per_epoch, nb_epoch, \\\n",
    "                                  nb_val_samples=nb_val_samples, validation_data=val_gen, nb_worker=nb_worker, \\\n",
    "                                  pickle_safe=False, callbacks=ls_callbacks)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data with a python generator so we can do data augmentation on the fly\n",
    "\n",
    "class My_dataset_gen():\n",
    "    \"\"\"\n",
    "    To be strict, My_dataset_gen is not a real generator (does not call yield) but an iterator\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 path2csv,\n",
    "                 batch_size,\n",
    "                 crop_input,\n",
    "                 training=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.crop_input = crop_input\n",
    "        \n",
    "        # Load the CSV\n",
    "        self.path2csv = path2csv\n",
    "        df = pd.read_csv(self.path2csv)\n",
    "        self.dataset = df.to_dict(orient='records') # This is a list of dict\n",
    "        \n",
    "        self.position = 0\n",
    "        self.size_epoch = len(self.dataset)\n",
    "        self.training = training\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "\n",
    "        number_of_samples = 0\n",
    "        X_l = list()\n",
    "        Y_l = list()\n",
    "        \n",
    "        while number_of_samples < self.batch_size:\n",
    "            if self.position == self.size_epoch:\n",
    "                shuffle(self.dataset)\n",
    "                self.position = 0\n",
    "                \n",
    "            sample = self.dataset[self.position]\n",
    "            \n",
    "            rand_val = random.random()\n",
    "            \n",
    "            if not self.training or rand_val <= 1-sample['Probability appearance']: # This way we eliminate biases toward more frequent values\n",
    "                # E.g. sample['Probability appearance'] = 0.25. This means it appears  only 25% of the times in the dataset\n",
    "                # but I want to balance it, so I do 1-0.25= 0.75. Comparing with a random value between 0 and 1, this sample \n",
    "                # will be used (with data augmentation techniques) the 75% of the times. Category samples with a high \n",
    "                # 'Probability appearance' will be more likely rejected, but because of there are more samples of that \n",
    "                # category doesn't matter. On average all categories should be balanced.\n",
    "                image = imread(sample['Updated image path'])\n",
    "                image = self._crop(image)\n",
    "                angle = sample['Steering angle']\n",
    "                \n",
    "                if self.training:\n",
    "                    image, angle = self._random_transform(image, angle)\n",
    "                    \n",
    "                image = self._normalize(image)\n",
    "                \n",
    "                X_l.append(image)\n",
    "                Y_l.append(angle)\n",
    "                \n",
    "                number_of_samples += 1\n",
    "                \n",
    "            self.position += 1\n",
    "            \n",
    "            \n",
    "        X = np.array(X_l) # Current shape follows tf dim_ordering: (samples, height, width, channels)\n",
    "        Y = np.array(Y_l)\n",
    "        \n",
    "        return (X,Y)\n",
    "            \n",
    "    \n",
    "    def _normalize(self, x, a=0, b=1):\n",
    "        x = x.astype(np.float32)\n",
    "        return a + (x-x.min())*(b-a)/(x.max() - x.min())\n",
    "    \n",
    "    def _crop(self, x):\n",
    "            return x[50:150, :] # See Explore dataset + Experimental setup.ipynb\n",
    "\n",
    "    def _random_transform(self, image, angle):\n",
    "        return image, angle # TODO to be completed\n",
    "    \n",
    "    def get_image_shape(self):\n",
    "        \n",
    "        temp = imread(self.dataset[0]['Updated image path'])\n",
    "        \n",
    "        if self.crop_input:\n",
    "            return self._crop(temp).shape\n",
    "        else:\n",
    "            return temp.shape\n",
    "        \n",
    "    def get_epoch_size(self):\n",
    "        return self.size_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's perform a quick test to see if all the pieces work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path2csv_training = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_training.csv\"\n",
    "path2csv_validation = \"/home/ubuntu/SDC/Behavioral-Cloning-Dataset/driving_log_validation.csv\"\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 2\n",
    "limit_train = 10\n",
    "limit_val = 10\n",
    "\n",
    "train_gen = My_dataset_gen(path2csv_training, batch_size, crop_input=True)\n",
    "val_gen = My_dataset_gen(path2csv_validation, batch_size, crop_input=True, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 26050\n",
      "Number of validation samples: 6513\n",
      "Shape of the images:  (100, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some statistics about the dataset\n",
    "\n",
    "print(\"Number of training samples: %d\" % (train_gen.get_epoch_size()))\n",
    "print(\"Number of validation samples: %d\" % (val_gen.get_epoch_size()))\n",
    "print(\"Shape of the images: \", train_gen.get_image_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_16 (Convolution2D) (None, 48, 158, 24)   1824        convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 48, 158, 24)   0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 22, 77, 36)    21636       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 22, 77, 36)    0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 9, 37, 48)     43248       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 9, 37, 48)     0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 7, 35, 64)     27712       activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 7, 35, 64)     0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 5, 33, 64)     36928       activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 5, 33, 64)     0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 10560)         0           activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 1164)          12293004    flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 1164)          0           dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 100)           116500      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 100)           0           dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 50)            5050        activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 50)            0           dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 10)            510         activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 10)            0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 1)             11          activation_36[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 12,546,423\n",
      "Trainable params: 12,546,423\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_nvidia(train_gen.get_image_shape())\n",
    "optimizer = get_optimizer()\n",
    "\n",
    "# Just have a look at our model before training:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 2s - loss: 0.1644 - val_loss: 0.0284\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 1s - loss: 0.0025 - val_loss: 0.0240\n"
     ]
    }
   ],
   "source": [
    "history, model = train_model(train_gen, val_gen, batch_size, epochs, model, optimizer, limit_train, limit_val)\n",
    "# There is no need to save the model. It's already saved by the callbacks provided in fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_vs_epochs(training_loss, validation_loss)\n",
    "    plt.plot(range(1,len(training_loss)+1), training_loss, 'b')\n",
    "    plt.xticks(range(1,len(training_loss)+1))\n",
    "    plt.hold(True)\n",
    "    plt.plot(range(1,len(training_loss)+1), validation_loss, 'g')\n",
    "    plt.hold(False)\n",
    "    _ = plt.legend((\"Training\", \"Validation\"), loc='lower right')\n",
    "    _ = plt.ylabel(\"Loss\")\n",
    "    _ = plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.16436520223505796, 0.0024508317932486535],\n",
       " 'lr': [0.001, 0.001],\n",
       " 'val_loss': [0.02836389158037491, 0.024034411087632178]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plot_loss_vs_epochs(history.history['loss'], history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do the real training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = My_dataset_gen(path2csv_training, batch_size, crop_input=True)\n",
    "val_gen = My_dataset_gen(path2csv_validation, batch_size, crop_input=True, training=False)\n",
    "\n",
    "model = get_model_nvidia(train_gen.get_image_shape())\n",
    "optimizer = get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history, model = train_model(train_gen, val_gen, batch_size, epochs, model, optimizer)\n",
    "# There is no need to save the model. It's already saved by the callbacks provided in fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_vs_epochs(training_loss, validation_loss)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-TensorFlow-Lab]",
   "language": "python",
   "name": "conda-env-CarND-TensorFlow-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
